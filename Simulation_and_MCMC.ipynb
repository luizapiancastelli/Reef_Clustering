{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Reef Clustering: Data generation and MCMC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook shows how to simulate data from a Dirichlet\n",
    "mixture model and run the MCMC algorithm in the paper *A Bayesian latent allocation model for clustering compositional data with application to the Great Barrier Reef* by Piancastelli, Friel, Vercelloni, Mengersen and Mira. These steps are implemented in Python to leverage of the `numba` high performance compiler. \n",
    "Results are then stored and read into `R` for post-processing via the `label.switching` library and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Python libraries\n",
    "import os\n",
    "import scipy.stats as stats\n",
    "import numpy \n",
    "import math\n",
    "import time\n",
    "from numba import jit\n",
    "import random\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cluster import KMeans\n",
    "import dirichlet\n",
    "import pickle\n",
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in Python scripts with the functions\n",
    "from MH_z import *\n",
    "from MH_rho import *\n",
    "from Main import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Simulating from a Dirichlet Mixture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After loading the necessary libraries and scripts, we simulate 400 observations from a 4-dimensional Dirichlet mixture with two components and parameters (5,5,5,5) and (5, 5,1,1) in the next code chunk. The main functions are those in `Main.py` for which a brief documentation is provided. We can access this by calling `help` on them. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function sim_dirichlet_mixture in module Main:\n",
      "\n",
      "sim_dirichlet_mixture(rho, n)\n",
      "    Simulates data from a Dirichlet mixture model. \n",
      "    \n",
      "    rho: numpy array where the number of rows is the number of mixture components\n",
      "    n: sample size\n",
      "    \n",
      "    Output: dictionary. 'data' is the simulated compositional data, 'z' are the cluster allocations.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(sim_dirichlet_mixture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simulate some data\n",
    "rho_true = numpy.array([[5, 5, 5, 5],\n",
    "                        [5, 5, 1, 1]])\n",
    "sim = sim_dirichlet_mixture(rho_true, 400)\n",
    "p = sim['data']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cluster allocations are simulated at random and can be obtained by accessing `z` in the `sim` dictionary. Alternatively, we can read in the reef data sets from `Data\\`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Running MCMC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run `m` MCMC chains, we create a list of this length containing initial parameter values for each chain. This can be done using the function `initial_values`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 2 #Number of MCMC chains \n",
    "k = 2 #Number of clusters to fit the model\n",
    "\n",
    "inits = initial_values(p, k, m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to parallelize our main function `MCMC_dirichlet` over the initial values list. In the function's description we can check the required arguments and expected output. We set the chain configurations and\n",
    "hyperparameters in the next code chunk. The default values of `perv_var` and `sigma_a` of 0.7 and 0.5 will be used in this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "burn_in = 100000\n",
    "thin = 200\n",
    "chain_output = 1000\n",
    "\n",
    "hyperparams_dict = {'delta': 0.5,\n",
    "                   'gamma': 0.2,\n",
    "                   'phi': 5.0,\n",
    "                   'lambda': 6.0}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next chunk, we refer to the `multiprocessing` library to run the `m` chains in parallel. It can take some minutes depending on how many iterations are required but progress information will be printed on screen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Burn in step:  10000\n",
      "Burn in step:  10000\n",
      "Burn in step:  20000\n",
      "Burn in step:  20000\n",
      "Burn in step:  30000\n",
      "Burn in step:  30000\n",
      "Burn in step:  40000\n",
      "Burn in step:  40000\n",
      "Burn in step:  50000\n",
      "Burn in step:  50000\n",
      "Burn in step:  60000\n",
      "Burn in step:  60000\n",
      "Burn in step:  70000\n",
      "Burn in step:  70000\n",
      "Burn in step:  80000\n",
      "Burn in step:  80000\n",
      "Burn in step:  90000\n",
      "Burn in step:  90000\n",
      "Burn in step:  100000\n",
      "Step:  0\n",
      "Burn in step:  100000\n",
      "Step:  0\n",
      "Step:  10000\n",
      "Step:  10000\n",
      "Step:  20000\n",
      "Step:  20000\n",
      "Step:  30000\n",
      "Step:  30000\n",
      "Step:  40000\n",
      "Step:  40000\n",
      "Step:  50000\n",
      "Step:  50000\n",
      "Step:  60000\n",
      "Step:  60000\n",
      "Step:  70000\n",
      "Step:  70000\n",
      "Step:  80000\n",
      "Step:  80000\n",
      "Step:  90000\n",
      "Step:  90000\n",
      "Step:  100000\n",
      "Step:  100000\n",
      "Step:  110000\n",
      "Step:  110000\n",
      "Step:  120000\n",
      "Step:  120000\n",
      "Step:  130000\n",
      "Step:  130000\n",
      "Step:  140000\n",
      "Step:  140000\n",
      "Step:  150000\n",
      "Step:  150000\n",
      "Step:  160000\n",
      "Step:  160000\n",
      "Step:  170000\n",
      "Step:  170000\n",
      "Step:  180000\n",
      "Step:  180000\n",
      "Step:  190000\n",
      "Step:  190000\n"
     ]
    }
   ],
   "source": [
    "# Parallellize over the length of inits list\n",
    "n_cores = 2 # Set the number of cores \n",
    "\n",
    "pool = mp.Pool(n_cores)  # Number of processors to use\n",
    "results = []\n",
    "results = pool.starmap_async( MCMC_dirichlet, [(i, inits, p, burn_in,\n",
    "                                      thin, chain_output, hyperparams_dict) for i in range(m)]).get()\n",
    "pool.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results can be saved at read into R for post-processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name =\"Example results/MCMC_example.p\"\n",
    "pickle.dump(results,open(file_name,'wb'), protocol=2)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
